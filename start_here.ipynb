{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Dataset\n",
    "This notebook should take the bare minimum to create the data set for use with philly-landlord-spotter.com\n",
    "\n",
    "### Prerequisites\n",
    "* Use pip to install `tqdm`\n",
    "* `opa_properties_public.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Run the following code block using `shift+enter`.\n",
    "\n",
    "This block imports the imports and puts the needed functions into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def json_creator(source, output):\n",
    "    data = {}\n",
    "    with open(source, mode='r') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        line_count = 0\n",
    "        for row in tqdm(csv_reader, total=581456):\n",
    "            if line_count != 0: # The first iteration needs too ignore the csv headers\n",
    "                if row[\"owner_1\"].strip() not in data.keys():\n",
    "                    address = row['location'].strip()  # So it makes more sense\n",
    "\n",
    "                    data[row[\"owner_1\"].strip()] = {\n",
    "                        'total_properties': 1,\n",
    "                        'properties': {\n",
    "                            address: {\n",
    "                                'location': [row['lat'].strip(), row['lng'].strip()],\n",
    "                                'category': row['category_code_description'].strip(),\n",
    "                                'owner_2': row['owner_2'].strip(),\n",
    "                                'sale_date': row['sale_date'].strip(),\n",
    "                                'sale_price': row['sale_price'].strip(),\n",
    "                                'year_built': row['year_built'].strip(),\n",
    "                                'year_built_estimate': row['year_built_estimate'].strip(),\n",
    "                                'recording_date': row['recording_date'],\n",
    "                                'zip_code': row['zip_code']\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                else:\n",
    "                    # Setting the data to var names for easier reading\n",
    "                    owner_1 = data[row['owner_1'].strip()]\n",
    "                    lat = row['lat'].strip()\n",
    "                    long = row['lng'].strip()\n",
    "                    category_code_description = row['category_code_description'].strip()\n",
    "                    owner_2 = row['owner_2'].strip()\n",
    "                    sale_date = row['sale_date'].strip()\n",
    "                    sale_price = row['sale_price'].strip()\n",
    "                    year_built = row['year_built'].strip()\n",
    "                    year_built_estimate = row['year_built_estimate'].strip()\n",
    "                    recording_date = row['recording_date']\n",
    "                    zip_code = row['zip_code']\n",
    "\n",
    "                    # Update and add values\n",
    "                    owner_1['total_properties'] += 1\n",
    "                    owner_1['properties'][row['location']] = {\n",
    "                                'location': [lat, long],\n",
    "                                'category': category_code_description,\n",
    "                                'owner_2': owner_2,\n",
    "                                'sale_date': sale_date,\n",
    "                                'sale_price': sale_price,\n",
    "                                'year_built': year_built,\n",
    "                                'year_built_estimate': year_built_estimate,\n",
    "                                'recording_date': recording_date,\n",
    "                                'zip_code': zip_code\n",
    "                            }\n",
    "            line_count += 1\n",
    "\n",
    "    with open(output, 'w') as file:\n",
    "        file.write(json.dumps(data))\n",
    "        \n",
    "def landlord_json_creator(source, output):\n",
    "    landlords = {}\n",
    "\n",
    "    with open(source, mode=\"r\") as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        line_count = 0\n",
    "        for row in tqdm(csv_reader, total=581456):\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            if row[\"owner_1\"] not in landlords.keys():\n",
    "                landlords[row[\"owner_1\"].strip()] = 1\n",
    "                line_count += 1\n",
    "            else:\n",
    "                try:\n",
    "                    landlord_prop_count = landlords[row[\"owner_1\"].strip()]\n",
    "                    landlords[row[\"owner_1\"].strip()] = landlord_prop_count + 1\n",
    "                except:\n",
    "                    print(row[\"owner_1\"].strip(), \"is missing a count.\")\n",
    "                line_count += 1\n",
    "        sorted_landlords = sorted(landlords.items(), key=lambda x: x[1], reverse=True)\n",
    "    with open(output, 'w') as file:\n",
    "        file.write(json.dumps(sorted_landlords))\n",
    "        \n",
    "def property_json_creator(source, output):\n",
    "    properties = []\n",
    "\n",
    "    with open(source, mode=\"r\") as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        line_count = 0\n",
    "        for row in tqdm(csv_reader, total=581456):\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            properties.append(row['location'].strip())\n",
    "            line_count += 1\n",
    "    with open(output, 'w') as file:\n",
    "        file.write(json.dumps(properties))\n",
    "\n",
    "def remove_one_off_landlords(source, output, significant_property_count):\n",
    "    with open(source, mode='r') as file:\n",
    "        data = file.read()\n",
    "    landlords_and_properties = json.loads(data)\n",
    "    landlord_count = len(landlords_and_properties.keys())\n",
    "    significant_landlords = {}\n",
    "    for landlord in tqdm(landlords_and_properties, total=landlord_count):\n",
    "        if landlords_and_properties[landlord]['total_properties'] >= significant_property_count:\n",
    "            significant_landlords[landlord] = {\n",
    "                'total_properties': landlords_and_properties[landlord]['total_properties'],\n",
    "                'properties': landlords_and_properties[landlord]['properties']\n",
    "            }\n",
    "    print('Significance Threshold: ', significant_property_count, 'Properties Owned')\n",
    "    print('Significant Landlords: ', len(significant_landlords))\n",
    "    with open(output, 'w') as file:\n",
    "            file.write(json.dumps(significant_landlords))\n",
    "            \n",
    "def significant_landlords_generator(source, output, significant_property_count):\n",
    "    with open(source, mode='r') as file:\n",
    "        data = file.read()\n",
    "    landlords_and_properties = json.loads(data)\n",
    "    landlord_count = len(landlords_and_properties)\n",
    "    significant_landlords = []\n",
    "    for landlord in tqdm(landlords_and_properties, total=landlord_count):\n",
    "        if landlord[1] >= significant_property_count:\n",
    "            significant_landlords.append(landlord)\n",
    "    print('Significance Threshold: ', significant_property_count, 'Properties Owned')\n",
    "    print('Significant Landlords: ', len(significant_landlords))\n",
    "    with open(output, 'w') as file:\n",
    "            file.write(json.dumps(significant_landlords))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Run the following code block using `shift+enter`.\n",
    "\n",
    "This block runs the intital JSON creator for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581456/581456 [00:14<00:00, 39770.09it/s]\n"
     ]
    }
   ],
   "source": [
    "json_creator('./data_sets/opa_properties_public.csv', './data_sets/landlords_and_properties.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3\n",
    "Warning: Step 2 must be run successfully before this.\n",
    "\n",
    "Run the following code block using `shift+enter`.\n",
    "\n",
    "This block creates a JSON object of `owner_1`'s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581456/581456 [00:08<00:00, 68582.72it/s]\n"
     ]
    }
   ],
   "source": [
    "landlord_json_creator('./data_sets/opa_properties_public.csv', './data_sets/sorted_landlords.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4\n",
    "Warning: Step 2 must be run successfully before this.\n",
    "\n",
    "Run the following code block using `shift+enter`.\n",
    "\n",
    "This block creates a JSON object of properties in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 581456/581456 [00:08<00:00, 69940.63it/s]\n"
     ]
    }
   ],
   "source": [
    "property_json_creator('./data_sets/opa_properties_public.csv', './data_sets/properties.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5\n",
    "Warning: Step 2 must be run successfully before this.\n",
    "\n",
    "Run the following code block using `shift+enter`.\n",
    "\n",
    "This block creates a JSON object of signigant `owner_1`s in the dataset and their properties.\n",
    "\n",
    "Currently I have the signifigance on the website at `200`, so it's probably best to use that. I also don't quite remember where I use this, if anywhere rn but just in case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429982/429982 [00:00<00:00, 1555032.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance Threshold:  200 Properties Owned\n",
      "Significant Landlords:  16\n"
     ]
    }
   ],
   "source": [
    "remove_one_off_landlords('./data_sets/landlords_and_properties.json', './data_sets/significant_landlords.json', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6\n",
    "Warning: Step 3 must be run successfully before this.\n",
    "\n",
    "Run the following code block using `shift+enter`.\n",
    "\n",
    "This block creates a JSON object of signigant `owner_1`s in the dataset and their properties, then sorts it.\n",
    "\n",
    "Currently I have the signifigance on the website at `50`, so it's probably best to use that. This one is definitely used on the site."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 429983/429983 [00:00<00:00, 3228876.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Significance Threshold:  50 Properties Owned\n",
      "Significant Landlords:  23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "significant_landlords_generator('./data_sets/sorted_landlords.json', './data_sets/significant_sorted_landlords.json', 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrubbing PHA From Public Facing Maps\n",
    "\n",
    "To keep the privacy of some housing movements, we don't show this so easily.\n",
    "\n",
    "This isn't needed if you don't plan on working with these files."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1\n",
    "Run the following code block using `shift+enter`.\n",
    "\n",
    "This block imports the imports and puts the needed functions into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "def remove_entry(source, entry_to_remove):\n",
    "    data = json.load(open(source))\n",
    "    data.pop(entry_to_remove)\n",
    "    json.dump(data, open(source, 'w'))\n",
    "    \n",
    "def remove_significant_landlord(source, entry_to_remove):\n",
    "    data = json.load(open(source))\n",
    "    for sig_landlord in tqdm(data):\n",
    "        if sig_landlord[0] == entry_to_remove:\n",
    "            data.remove(sig_landlord)\n",
    "    json.dump(data, open(source, 'w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2\n",
    "Run the following code block using `shift+enter`. Also, this one takes a sec and won't output til its done.\n",
    "\n",
    "This block removes PHA from where it shouldn't be.\n",
    "\n",
    "If this is ran successfully once, it will fail it's second time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 22/23 [00:00<00:00, 96521.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "remove_entry('./data_sets/landlords_and_properties.json', \"PHILADELPHIA HOUSING AUTH\")\n",
    "remove_significant_landlord('./data_sets/significant_sorted_landlords.json', \"PHILADELPHIA HOUSING AUTH\")\n",
    "print('done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Done\n",
    "Assuming all of this runs correctly, it should be everything needed to get the site going. If there are any problems with anything, let me know. Removing the PHA stuff isn't entirely needed if you don't plan on working with it."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
