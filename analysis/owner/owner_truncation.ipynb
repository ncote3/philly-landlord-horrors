{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring owner_1 Truncation\n",
    "In this notebook I will be attempting to cross reference property assessment data with Business License data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import csv\n",
    "import re\n",
    "from fuzzywuzzy import fuzz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting Business License data into smaller JSON\n",
    "Only grabbing what I need at first from the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_useful_li_data(source, output):\n",
    "    data = {}\n",
    "    line_count = 0\n",
    "    with open(source, mode=\"r\") as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "        for row in tqdm(csv_reader, total=366036):\n",
    "            if line_count == 0:\n",
    "                line_count += 1\n",
    "            else:\n",
    "                if row[\"address\"].strip() not in data.keys():\n",
    "                    data[row[\"address\"].strip()] = {\n",
    "                        'total_address_entries': 1,\n",
    "                        'entries': {\n",
    "                            row[\"legalname\"].strip(): {\n",
    "                                'license_num': row['licensenum'].strip(),\n",
    "                                'license_type': row['licensetype'].strip(),\n",
    "                                'initial_issue_date': row['initialissuedate'].strip(),\n",
    "                                'most_recent_issue_date': row['mostrecentissuedate'].strip(),\n",
    "                                'expiration_date': row['expirationdate'].strip(),\n",
    "                                'inactive_date': row['inactivedate'].strip(),\n",
    "                                'license_status': row['licensestatus'].strip(),\n",
    "                                'parcel_id_num': row['parcel_id_num'].strip(),\n",
    "                                'opa_account_num': row['opa_account_num'].strip(),\n",
    "                                'opa_owner': row['opa_owner'].strip(),\n",
    "                                'number_of_units': row['numberofunits'].strip(),\n",
    "                                'legal_entity_type': row['legalentitytype'].strip(),\n",
    "                                'business_name': row['business_name'].strip(),\n",
    "                                'business_mailing_address': row['business_mailing_address'].strip()\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                else:\n",
    "                    # Setting the data to var names for easier reading\n",
    "                    address = data[row['address'].strip()]\n",
    "                    legal_name = row[\"legalname\"].strip()\n",
    "                    license_num = row['licensenum'].strip()\n",
    "                    license_type = row['licensetype'].strip()\n",
    "                    initial_issue_date = row['initialissuedate'].strip()\n",
    "                    most_recent_issue_date = row['mostrecentissuedate'].strip()\n",
    "                    expiration_date = row['expirationdate'].strip()\n",
    "                    inactive_date = row['inactivedate'].strip()\n",
    "                    license_status = row['licensestatus'].strip()\n",
    "                    parcel_id_num = row['parcel_id_num'].strip()\n",
    "                    opa_account_num = row['opa_account_num'].strip()\n",
    "                    opa_owner = row['opa_owner'].strip()\n",
    "                    number_of_units = row['numberofunits'].strip()\n",
    "                    legal_entity_type =  row['legalentitytype'].strip()\n",
    "                    business_name = row['business_name'].strip()\n",
    "                    business_mailing_address = row['business_mailing_address'].strip()\n",
    "\n",
    "                    # Update and add values\n",
    "                    address['total_address_entries'] += 1\n",
    "                    address['entries'][legal_name] = {\n",
    "                                'license_num': license_num,\n",
    "                                'license_type': license_type,\n",
    "                                'initial_issue_date': initial_issue_date,\n",
    "                                'most_recent_issue_date': most_recent_issue_date,\n",
    "                                'expiration_date': expiration_date,\n",
    "                                'inactive_date': inactive_date,\n",
    "                                'license_status': license_status,\n",
    "                                'parcel_id_num': parcel_id_num,\n",
    "                                'opa_account_num': opa_account_num,\n",
    "                                'opa_owner': opa_owner,\n",
    "                                'number_of_units': number_of_units,\n",
    "                                'legal_entity_type': legal_entity_type,\n",
    "                                'business_name': business_name,\n",
    "                                'business_mailing_address': business_mailing_address\n",
    "                            }\n",
    "                line_count += 1\n",
    "        print('There are ', line_count, 'in this dataset.')\n",
    "        with open(output, 'w+') as file:\n",
    "            file.write(json.dumps(data))         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 366036/366036 [00:04<00:00, 74558.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  366036 in this dataset.\n"
     ]
    }
   ],
   "source": [
    "get_useful_li_data('./../../data_sets/business_licenses.csv', './data/business_licenses.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging Business License Data with Property Assessment Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_PA_BL(PA_source, BL_source, output):\n",
    "    PA_data = json.load(open(PA_source))\n",
    "    BL_data = json.load(open(BL_source))\n",
    "    \n",
    "    count = 0\n",
    "    \n",
    "    for owner in tqdm(PA_data, total=len(PA_data)):\n",
    "        properties = PA_data[owner]['properties']\n",
    "        for address in properties:\n",
    "            if address in BL_data.keys():\n",
    "                PA_data[owner]['properties'][address]['business_license_entries'] = BL_data[address]\n",
    "                PA_data[owner]['properties'][address]['has_business_license_entry'] = True\n",
    "                count += 1\n",
    "            else:\n",
    "                PA_data[owner]['properties'][address]['business_license_entries'] = []\n",
    "                PA_data[owner]['properties'][address]['has_business_license_entry'] = False                            \n",
    "    json.dump(PA_data, open(output, 'w+'))\n",
    "    \n",
    "    print('There were ', count, ' entries linked.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 429982/429982 [00:00<00:00, 545912.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were  195341  entries linked.\n"
     ]
    }
   ],
   "source": [
    "merge_PA_BL('./../../data_sets/landlords_and_properties.json', './data/business_licenses.json', './data/PA_BL_landlords_and_properties.JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verifing the Previous Function\n",
    "I need to split the JSON into 2 because it is too large to open. Splitting it by having an match and not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_PA_BL_results(source, match_output):\n",
    "    data = json.load(open(source))\n",
    "    output = {}\n",
    "    split_count = 0\n",
    "    for owner in data:\n",
    "        entry_flag_count = 0\n",
    "        total_props = data[owner]['total_properties']\n",
    "        bl_props = {}\n",
    "        props = {}\n",
    "        for address in data[owner]['properties']:\n",
    "            if data[owner]['properties'][address]['has_business_license_entry'] is True:\n",
    "                entry_flag_count += 1\n",
    "                bl_props[address] = data[owner]['properties'][address]\n",
    "            else:\n",
    "                props[address] = data[owner]['properties'][address]\n",
    "        if entry_flag_count > 0:\n",
    "            split_count += 1\n",
    "            output[owner] = {\n",
    "                'total_properties': total_props,\n",
    "                'bl_property_count': entry_flag_count,\n",
    "                'business_license_properties': bl_props,\n",
    "                'other_properties': props\n",
    "            }\n",
    "    json.dump(output, open(match_output, 'w+'))\n",
    "    print('A total of ', split_count, 'things were split.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function tqdm.__del__ at 0x000001FB4F148820>\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\python38\\lib\\site-packages\\tqdm\\std.py\", line 1090, in __del__\n",
      "    self.close()\n",
      "  File \"c:\\python38\\lib\\site-packages\\tqdm\\std.py\", line 1303, in close\n",
      "    self.display(pos=0)\n",
      "  File \"c:\\python38\\lib\\site-packages\\tqdm\\std.py\", line 1481, in display\n",
      "    self.sp(self.__repr__() if msg is None else msg)\n",
      "  File \"c:\\python38\\lib\\site-packages\\tqdm\\std.py\", line 1093, in __repr__\n",
      "    return self.format_meter(**self.format_dict)\n",
      "  File \"c:\\python38\\lib\\site-packages\\tqdm\\std.py\", line 425, in format_meter\n",
      "    bool_prefix_colon_already = (prefix[-2:] == \": \")\n",
      "TypeError: 'int' object is not subscriptable\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A total of  134595 things were split.\n"
     ]
    }
   ],
   "source": [
    "split_PA_BL_results('./data/PA_BL_landlords_and_properties.JSON', './data/split_landlords_and_properties.JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting 'L' possibilities\n",
    "Find all the owners with 'L' at the end of the truncated name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_L_posibilities(source, output):\n",
    "    data = json.load(open(source))\n",
    "    out = []\n",
    "    count = 0\n",
    "    property_count = 0\n",
    "    L_count = 0\n",
    "    \n",
    "    raw_search_string_L = r\"\\b\" + \"L\" + r\"\\b$\"\n",
    "    \n",
    "    for owner in tqdm(data, total=len(data)):\n",
    "        match_output_L = re.search(raw_search_string_L, owner[0])\n",
    "        if match_output_L is not None:\n",
    "            out.append(owner)\n",
    "            count += 1\n",
    "            property_count += owner[1]\n",
    "            if match_output_L is not None:\n",
    "                L_count += 1\n",
    "\n",
    "    json.dump(out, open(output, 'w+'))\n",
    "    print('There are ', L_count, 'Ls in this dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 429983/429983 [00:00<00:00, 992858.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are  10594 Ls in this dataset\n"
     ]
    }
   ],
   "source": [
    "get_L_posibilities('./../../data_sets/sorted_landlords.json', './data/L_owner.json')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking for L's in the matched Business license owners"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_L_possiblities(L_source, BL_source, match_output, no_match_output):\n",
    "        L_data = json.load(open(L_source))\n",
    "        BL_data = json.load(open(BL_source))\n",
    "        match_o = {}\n",
    "        not_match_o = {}\n",
    "        count = 0\n",
    "        not_count = 0\n",
    "        for L_owner in tqdm(L_data, total=len(L_data)):\n",
    "            owner_name = L_owner[0]\n",
    "            for BL_owner in BL_data:\n",
    "                if BL_owner == owner_name and BL_data[BL_owner]['bl_property_count'] > 0:\n",
    "                    match_o[owner_name] = BL_data[BL_owner]\n",
    "                    count += 1\n",
    "                else:\n",
    "                    not_match_o[owner_name] = BL_data[BL_owner]\n",
    "                    not_count += 1\n",
    "        json.dump(match_o, open(match_output, 'w+'))\n",
    "        json.dump(not_match_o, open(no_match_output, 'w+'))\n",
    "        print('There were ', count, 'matches.')\n",
    "        print('There were ', not_count, 'not matches.')\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 10594/10594 [07:13<00:00, 24.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were  2847 matches.\n",
      "There were  1425896583 not matches.\n"
     ]
    }
   ],
   "source": [
    "match_L_possiblities('./data/L_owner.json', './data/split_landlords_and_properties.JSON', './data/L_split_match.JSON', './data/L_split_no_match.JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding L's with LLC Business License Entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_Ls_with_LLC_BL_entries(source, match_output, no_match_owner_output):\n",
    "    data = json.load(open(source))\n",
    "    count = 0\n",
    "    out = {}\n",
    "    raw_search_string_LLC = r\"\\b\" + \"LLC\" + r\"\\b\"\n",
    "    no_match_owners = []\n",
    "    no_match_count = 0\n",
    "    for owner in tqdm(data, total=len(data)):\n",
    "        match_count = 0\n",
    "        matches = {}\n",
    "        bl_props = data[owner]['business_license_properties']\n",
    "        for prop in bl_props:\n",
    "            entries = bl_props[prop]['business_license_entries']['entries']\n",
    "            entry_matches = {}\n",
    "            for entry in entries:\n",
    "                match_output_LLC_entry = re.search(raw_search_string_LLC, entry)\n",
    "                match_output_LLC_business_name = re.search(raw_search_string_LLC, entries[entry]['business_name'])\n",
    "                if match_output_LLC_entry is not None or match_output_LLC_business_name is not None:\n",
    "                    match_count += 1\n",
    "                    entry_matches[entry] = entries[entry]\n",
    "            if entry_matches != {}:\n",
    "                matches[prop] = entry_matches\n",
    "        if match_count > 0:\n",
    "            out[owner] = matches\n",
    "            count += 1\n",
    "        else:\n",
    "            no_match_count += 1\n",
    "            no_match_owners.append(owner)\n",
    "            \n",
    "    json.dump(out, open(match_output, 'w+'))\n",
    "    json.dump(no_match_owners, open(no_match_owner_output, 'w+'))\n",
    "    print('There were ', count, 'matches.')\n",
    "    print('There were ', no_match_count, 'not matches.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 2847/2847 [00:00<00:00, 33887.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were  625 matches.\n",
      "There were  2222 not matches.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "get_Ls_with_LLC_BL_entries('./data/L_split_match.JSON', './data/L_split_LLC_match.JSON', './data/L_split_no_LLC_match.JSON')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Fuzzy String Match Ranking to find actual matches\n",
    "I need to iterate over each PA owner and compare them to entries in each matched BL property entry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuzzy_match_owners(source, output, distance_lower_bound):\n",
    "    data = json.load(open(source))\n",
    "    out = {}\n",
    "    possible_matches_count = 0\n",
    "    entries_to_check_count = 0\n",
    "    for owner in tqdm(data, total=len(data)):\n",
    "        fuzzy_ratios = {}\n",
    "        for address in data[owner]:\n",
    "            for entry in data[owner][address]:\n",
    "                entry_owner_object = data[owner][address][entry]\n",
    "                entry_business_name = data[owner][address][entry]['business_name']\n",
    "                license_type = data[owner][address][entry]['license_type']\n",
    "                legal_entity_type = data[owner][address][entry]['legal_entity_type']\n",
    "                license_status = data[owner][address][entry]['license_status']\n",
    "                business_mailing_address = data[owner][address][entry]['business_mailing_address']\n",
    "                \n",
    "                is_rental = False\n",
    "                is_active_license = False\n",
    "                if license_type == \"Rental\":\n",
    "                    is_rental = True\n",
    "                if license_status == \"Active\":\n",
    "                    is_active_license = True\n",
    "                \n",
    "                \n",
    "                entry_owner_fuzz_ratio = fuzz.ratio(owner, entry)\n",
    "                entry_business_name_fuzz_ratio = fuzz.ratio(owner, entry_business_name)\n",
    "                \n",
    "                if entry_owner_fuzz_ratio >= distance_lower_bound or entry_business_name_fuzz_ratio >= distance_lower_bound:\n",
    "                    entries_to_check_count += 1\n",
    "                    fuzzy_ratios[entry] = {\n",
    "                        'entry_owner_fuzz_ratio': entry_owner_fuzz_ratio,\n",
    "                        'business_name': entry_business_name,\n",
    "                        'business_name_fuzz_ratio': entry_business_name_fuzz_ratio,\n",
    "                        'is_rental': is_rental,\n",
    "                        'is_active_license':is_active_license,\n",
    "                        'legal_entity_type': legal_entity_type,\n",
    "                        'address': address\n",
    "                    }\n",
    "        if fuzzy_ratios != {}:\n",
    "            possible_matches_count += 1\n",
    "            out[owner] = fuzzy_ratios\n",
    "    json.dump(out, open(output, 'w+'))\n",
    "    print('There were ', possible_matches_count, 'possible matches with a score >= ', distance_lower_bound, '.')\n",
    "    print(\"That's \", entries_to_check_count, 'entries to check by hand! Wooohoooo!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 625/625 [00:00<00:00, 89270.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were  201 possible matches with a score >=  70 .\n",
      "That's  415 entries to check by hand! Wooohoooo!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "fuzzy_match_owners('./data/L_split_LLC_match.JSON', './data/fuzz_ratio_L_split_LLC_match.JSON', 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
